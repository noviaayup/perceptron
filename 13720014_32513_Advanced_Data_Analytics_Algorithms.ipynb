{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13720014_32513 Advanced Data Analytics Algorithms",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noviaayup/perceptron/blob/main/13720014_32513_Advanced_Data_Analytics_Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woLcJYb1ltLM"
      },
      "source": [
        "# **32513 Advanced Data Analytics Algorithms: Assignment 2**\n",
        "Implementation of Perceptron Model\n",
        "\n",
        "Name: Novia Pratiwi \n",
        "\n",
        "Student ID: 13720014"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQOkIjNxyZHb"
      },
      "source": [
        "**Perceptron Data Algorithms**\n",
        "\n",
        "In this code below, we'll introduce the Single-Layer Perceptron (aka \"Neuron\" or simply \"Perceptron\"), the most fundamental element of nearly all modern neural network and machine learning models.  We'll begin by loading the data, then visualise and actually implement the element from scratch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz7YgCDvIjC1",
        "outputId": "84d6b171-e54e-44ab-c279-1e64542e6f40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "def load_data():\n",
        "    URL_='https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
        "    data = pd.read_csv(URL_, header = None)\n",
        "    print(data)\n",
        "    \n",
        "    # make the dataset linearly separable\n",
        "    data = data[:100]\n",
        "    data[4] = np.where(data.iloc[:, -1]=='Iris-setosa', 0, 1)\n",
        "    data = np.asmatrix(data, dtype = 'float64')\n",
        "    return data\n",
        "data = load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       0    1    2    3               4\n",
            "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
            "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
            "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
            "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
            "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
            "..   ...  ...  ...  ...             ...\n",
            "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
            "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
            "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
            "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
            "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgNXGEM_3kyK"
      },
      "source": [
        "# **Building a predictor**\n",
        "\n",
        "Recall that we invented two predictors and we have nurtured our taste of selecting a data model to represent the relationship between the observed attributes and the targets to be to be predicted.\n",
        "\n",
        "Again we start with the two predictors (we simplify the denotation by calling them f0 and f1, but the definition remains the same as we encountered previously)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omxCuzTn3PFg"
      },
      "source": [
        "Building a predictor from data. We will prepare a simplified Iris dataset as before.\n",
        "\n",
        "using only 2 attributes,  ð‘‹0  and  ð‘‹1 ,\n",
        "considering classify setosa from versicolor (y==0, y==1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKnpffiDueOn"
      },
      "source": [
        "Now let us try the training framework on the simple dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ketxFq1R8lU"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "iris = load_iris()\n",
        "X, y = iris['data'], iris['target']\n",
        "two_class_index = np.logical_or(y == 0, y == 1)\n",
        "simple_X = X[two_class_index]\n",
        "simple_X = simple_X[:, 0:2]\n",
        "simple_y = y[two_class_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfnT95C3i0Zi"
      },
      "source": [
        "import numpy as np\n",
        " \n",
        " \n",
        "class Perceptron:\n",
        " \n",
        "    def __init__(self, learning_rate=0.01, n_iters=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.activation_func = self._unit_step_func\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        " \n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        " \n",
        "        # init parameters\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        " \n",
        "        y_ = np.array([1 if i > 0 else 0 for i in y])\n",
        " \n",
        "        for _ in range(self.n_iters):\n",
        "            \n",
        "            for idx, x_i in enumerate(X):\n",
        " \n",
        "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
        "                y_predicted = self.activation_func(linear_output)\n",
        "                \n",
        "                # Perceptron update rule\n",
        "                update = self.lr * (y_[idx] - y_predicted)\n",
        " \n",
        "                self.weights += update * x_i\n",
        "                self.bias += update\n",
        " \n",
        "    def predict(self, X):\n",
        "        linear_output = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self.activation_func(linear_output)\n",
        "        return y_predicted\n",
        " \n",
        "    def _unit_step_func(self, x):\n",
        "        return np.where(x>=0, 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmCwW1_61xxt",
        "outputId": "d4b3f556-19d4-4737-bca3-8d3e3a4a1f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(X[:, 0][y == 0] * X[:, 1][y == 0], X[:, 2][y == 0] * X[:, 3][y == 0], 'r.', label=\"Setosa\")\n",
        "plt.plot(X[:, 0][y == 1] * X[:, 1][y == 1], X[:, 2][y == 1] * X[:, 3][y == 1], 'g.', label=\"Virginica\")\n",
        "plt.plot(X[:, 0][y == 2] * X[:, 1][y == 2], X[:, 2][y == 2] * X[:, 3][y == 2], 'b.', label=\"Versicolor\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b89AUqiP1j4m"
      },
      "source": [
        "# **Visualisation Helper**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bf1SVv21u_o"
      },
      "source": [
        "dataset = load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyyUC50O1lxP"
      },
      "source": [
        "X = dataset.data\n",
        "y = dataset.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb-EZqnz4y_T",
        "outputId": "b826cde5-3af8-409c-d3f9-9f13bd7b5841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "import plotly.express as px\n",
        "df = px.data.iris()\n",
        "fig = px.scatter(df, x=\"sepal_width\", y=\"sepal_length\", color=\"species\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"039b282a-8da4-435c-8b29-035d5b141bac\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"039b282a-8da4-435c-8b29-035d5b141bac\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '039b282a-8da4-435c-8b29-035d5b141bac',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"species=setosa<br>sepal_width=%{x}<br>sepal_length=%{y}\", \"legendgroup\": \"species=setosa\", \"marker\": {\"color\": \"#636efa\", \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"species=setosa\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3.0, 3.0, 4.0, 4.4, 3.9, 3.5, 3.8, 3.8, 3.4, 3.7, 3.6, 3.3, 3.4, 3.0, 3.4, 3.5, 3.4, 3.2, 3.1, 3.4, 4.1, 4.2, 3.1, 3.2, 3.5, 3.1, 3.0, 3.4, 3.5, 2.3, 3.2, 3.5, 3.8, 3.0, 3.8, 3.2, 3.7, 3.3], \"xaxis\": \"x\", \"y\": [5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.8, 4.8, 4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5.0, 5.0, 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5.0, 5.5, 4.9, 4.4, 5.1, 5.0, 4.5, 4.4, 5.0, 5.1, 4.8, 5.1, 4.6, 5.3, 5.0], \"yaxis\": \"y\"}, {\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"species=versicolor<br>sepal_width=%{x}<br>sepal_length=%{y}\", \"legendgroup\": \"species=versicolor\", \"marker\": {\"color\": \"#EF553B\", \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"species=versicolor\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [3.2, 3.2, 3.1, 2.3, 2.8, 2.8, 3.3, 2.4, 2.9, 2.7, 2.0, 3.0, 2.2, 2.9, 2.9, 3.1, 3.0, 2.7, 2.2, 2.5, 3.2, 2.8, 2.5, 2.8, 2.9, 3.0, 2.8, 3.0, 2.9, 2.6, 2.4, 2.4, 2.7, 2.7, 3.0, 3.4, 3.1, 2.3, 3.0, 2.5, 2.6, 3.0, 2.6, 2.3, 2.7, 3.0, 2.9, 2.9, 2.5, 2.8], \"xaxis\": \"x\", \"y\": [7.0, 6.4, 6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5.0, 5.9, 6.0, 6.1, 5.6, 6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7, 6.0, 5.7, 5.5, 5.5, 5.8, 6.0, 5.4, 6.0, 6.7, 6.3, 5.6, 5.5, 5.5, 6.1, 5.8, 5.0, 5.6, 5.7, 5.7, 6.2, 5.1, 5.7], \"yaxis\": \"y\"}, {\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"species=virginica<br>sepal_width=%{x}<br>sepal_length=%{y}\", \"legendgroup\": \"species=virginica\", \"marker\": {\"color\": \"#00cc96\", \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"species=virginica\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [3.3, 2.7, 3.0, 2.9, 3.0, 3.0, 2.5, 2.9, 2.5, 3.6, 3.2, 2.7, 3.0, 2.5, 2.8, 3.2, 3.0, 3.8, 2.6, 2.2, 3.2, 2.8, 2.8, 2.7, 3.3, 3.2, 2.8, 3.0, 2.8, 3.0, 2.8, 3.8, 2.8, 2.8, 2.6, 3.0, 3.4, 3.1, 3.0, 3.1, 3.1, 3.1, 2.7, 3.2, 3.3, 3.0, 2.5, 3.0, 3.4, 3.0], \"xaxis\": \"x\", \"y\": [6.3, 5.8, 7.1, 6.3, 6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5, 7.7, 7.7, 6.0, 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2, 7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6.0, 6.9, 6.7, 6.9, 5.8, 6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"sepal_width\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"sepal_length\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('039b282a-8da4-435c-8b29-035d5b141bac');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-KcshT6xBky"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def viz_hypo(score_func, pred_func, X_samples, y_samples):\n",
        "    \"\"\"\n",
        "    X_samples is to provide a range\n",
        "    \"\"\"\n",
        "    # visualisation of the model behaviour\n",
        "    x0_min, x1_min = np.min(X_samples, axis=0)\n",
        "    x0_max, x1_max = np.max(X_samples, axis=0)\n",
        "\n",
        "    xx, yy = np.meshgrid(np.arange(x0_min - 0.1, x0_max + 0.1, 0.02),\n",
        "                        np.arange(x1_min - 0.1, x1_max + 0.1, 0.02))\n",
        "    \n",
        "    grid_coord = np.stack((xx.flatten(), yy.flatten())).T\n",
        "    zz_c = pred_func(grid_coord).reshape(xx.shape)\n",
        "    zz_v = score_func(grid_coord).reshape(xx.shape)\n",
        "\n",
        "    fig1, ax1 = plt.subplots(constrained_layout=True)\n",
        "    C = ax1.contourf(xx, yy, zz_v) \n",
        "    C2 = ax1.contour(xx, yy, zz_v, colors=('k', ), linewidths=2)\n",
        "    ax1.clabel(C2, inline=True, fontsize=10)\n",
        "\n",
        "    fig2, ax2 = plt.subplots(constrained_layout=True)\n",
        "    C = ax2.contourf(xx, yy, zz_c) \n",
        "    C2 = ax2.contour(xx, yy, zz_c, colors=('k', ), linewidths=2)\n",
        "    ax2.clabel(C2, inline=True, fontsize=10)\n",
        "\n",
        "    # Draw the training samples\n",
        "    ax1.scatter(X_samples[:, 0], X_samples[:, 1], c=y_samples, linewidth=1, edgecolor='k')\n",
        "    ax2.scatter(X_samples[:, 0], X_samples[:, 1], c=y_samples, linewidth=1, edgecolor='k')\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1UmKJbe1n7U",
        "outputId": "a4a09030-a60d-4c1c-9db4-bfc60da63543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "import plotly.express as px\n",
        "df = px.data.iris()\n",
        "fig = px.scatter_matrix(df, dimensions=[\"sepal_width\", \"sepal_length\", \"petal_width\", \"petal_length\"], color=\"species\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"8ed00c9b-9c16-4568-908f-797483a225ab\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"8ed00c9b-9c16-4568-908f-797483a225ab\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '8ed00c9b-9c16-4568-908f-797483a225ab',\n",
              "                        [{\"dimensions\": [{\"axis\": {\"matches\": true}, \"label\": \"sepal_width\", \"values\": [3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3.0, 3.0, 4.0, 4.4, 3.9, 3.5, 3.8, 3.8, 3.4, 3.7, 3.6, 3.3, 3.4, 3.0, 3.4, 3.5, 3.4, 3.2, 3.1, 3.4, 4.1, 4.2, 3.1, 3.2, 3.5, 3.1, 3.0, 3.4, 3.5, 2.3, 3.2, 3.5, 3.8, 3.0, 3.8, 3.2, 3.7, 3.3]}, {\"axis\": {\"matches\": true}, \"label\": \"sepal_length\", \"values\": [5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.8, 4.8, 4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5.0, 5.0, 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5.0, 5.5, 4.9, 4.4, 5.1, 5.0, 4.5, 4.4, 5.0, 5.1, 4.8, 5.1, 4.6, 5.3, 5.0]}, {\"axis\": {\"matches\": true}, \"label\": \"petal_width\", \"values\": [0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.4, 0.4, 0.3, 0.3, 0.3, 0.2, 0.4, 0.2, 0.5, 0.2, 0.2, 0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.1, 0.2, 0.1, 0.2, 0.2, 0.1, 0.2, 0.2, 0.3, 0.3, 0.2, 0.6, 0.4, 0.3, 0.2, 0.2, 0.2, 0.2]}, {\"axis\": {\"matches\": true}, \"label\": \"petal_length\", \"values\": [1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.6, 1.4, 1.1, 1.2, 1.5, 1.3, 1.4, 1.7, 1.5, 1.7, 1.5, 1.0, 1.7, 1.9, 1.6, 1.6, 1.5, 1.4, 1.6, 1.6, 1.5, 1.5, 1.4, 1.5, 1.2, 1.3, 1.5, 1.3, 1.5, 1.3, 1.3, 1.3, 1.6, 1.9, 1.4, 1.6, 1.4, 1.5, 1.4]}], \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"species=setosa<br>%{xaxis.title.text}=%{x}<br>%{yaxis.title.text}=%{y}\", \"legendgroup\": \"species=setosa\", \"marker\": {\"color\": \"#636efa\", \"symbol\": \"circle\"}, \"name\": \"species=setosa\", \"showlegend\": true, \"type\": \"splom\"}, {\"dimensions\": [{\"axis\": {\"matches\": true}, \"label\": \"sepal_width\", \"values\": [3.2, 3.2, 3.1, 2.3, 2.8, 2.8, 3.3, 2.4, 2.9, 2.7, 2.0, 3.0, 2.2, 2.9, 2.9, 3.1, 3.0, 2.7, 2.2, 2.5, 3.2, 2.8, 2.5, 2.8, 2.9, 3.0, 2.8, 3.0, 2.9, 2.6, 2.4, 2.4, 2.7, 2.7, 3.0, 3.4, 3.1, 2.3, 3.0, 2.5, 2.6, 3.0, 2.6, 2.3, 2.7, 3.0, 2.9, 2.9, 2.5, 2.8]}, {\"axis\": {\"matches\": true}, \"label\": \"sepal_length\", \"values\": [7.0, 6.4, 6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5.0, 5.9, 6.0, 6.1, 5.6, 6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7, 6.0, 5.7, 5.5, 5.5, 5.8, 6.0, 5.4, 6.0, 6.7, 6.3, 5.6, 5.5, 5.5, 6.1, 5.8, 5.0, 5.6, 5.7, 5.7, 6.2, 5.1, 5.7]}, {\"axis\": {\"matches\": true}, \"label\": \"petal_width\", \"values\": [1.4, 1.5, 1.5, 1.3, 1.5, 1.3, 1.6, 1.0, 1.3, 1.4, 1.0, 1.5, 1.0, 1.4, 1.3, 1.4, 1.5, 1.0, 1.5, 1.1, 1.8, 1.3, 1.5, 1.2, 1.3, 1.4, 1.4, 1.7, 1.5, 1.0, 1.1, 1.0, 1.2, 1.6, 1.5, 1.6, 1.5, 1.3, 1.3, 1.3, 1.2, 1.4, 1.2, 1.0, 1.3, 1.2, 1.3, 1.3, 1.1, 1.3]}, {\"axis\": {\"matches\": true}, \"label\": \"petal_length\", \"values\": [4.7, 4.5, 4.9, 4.0, 4.6, 4.5, 4.7, 3.3, 4.6, 3.9, 3.5, 4.2, 4.0, 4.7, 3.6, 4.4, 4.5, 4.1, 4.5, 3.9, 4.8, 4.0, 4.9, 4.7, 4.3, 4.4, 4.8, 5.0, 4.5, 3.5, 3.8, 3.7, 3.9, 5.1, 4.5, 4.5, 4.7, 4.4, 4.1, 4.0, 4.4, 4.6, 4.0, 3.3, 4.2, 4.2, 4.2, 4.3, 3.0, 4.1]}], \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"species=versicolor<br>%{xaxis.title.text}=%{x}<br>%{yaxis.title.text}=%{y}\", \"legendgroup\": \"species=versicolor\", \"marker\": {\"color\": \"#EF553B\", \"symbol\": \"circle\"}, \"name\": \"species=versicolor\", \"showlegend\": true, \"type\": \"splom\"}, {\"dimensions\": [{\"axis\": {\"matches\": true}, \"label\": \"sepal_width\", \"values\": [3.3, 2.7, 3.0, 2.9, 3.0, 3.0, 2.5, 2.9, 2.5, 3.6, 3.2, 2.7, 3.0, 2.5, 2.8, 3.2, 3.0, 3.8, 2.6, 2.2, 3.2, 2.8, 2.8, 2.7, 3.3, 3.2, 2.8, 3.0, 2.8, 3.0, 2.8, 3.8, 2.8, 2.8, 2.6, 3.0, 3.4, 3.1, 3.0, 3.1, 3.1, 3.1, 2.7, 3.2, 3.3, 3.0, 2.5, 3.0, 3.4, 3.0]}, {\"axis\": {\"matches\": true}, \"label\": \"sepal_length\", \"values\": [6.3, 5.8, 7.1, 6.3, 6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5, 7.7, 7.7, 6.0, 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2, 7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6.0, 6.9, 6.7, 6.9, 5.8, 6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9]}, {\"axis\": {\"matches\": true}, \"label\": \"petal_width\", \"values\": [2.5, 1.9, 2.1, 1.8, 2.2, 2.1, 1.7, 1.8, 1.8, 2.5, 2.0, 1.9, 2.1, 2.0, 2.4, 2.3, 1.8, 2.2, 2.3, 1.5, 2.3, 2.0, 2.0, 1.8, 2.1, 1.8, 1.8, 1.8, 2.1, 1.6, 1.9, 2.0, 2.2, 1.5, 1.4, 2.3, 2.4, 1.8, 1.8, 2.1, 2.4, 2.3, 1.9, 2.3, 2.5, 2.3, 1.9, 2.0, 2.3, 1.8]}, {\"axis\": {\"matches\": true}, \"label\": \"petal_length\", \"values\": [6.0, 5.1, 5.9, 5.6, 5.8, 6.6, 4.5, 6.3, 5.8, 6.1, 5.1, 5.3, 5.5, 5.0, 5.1, 5.3, 5.5, 6.7, 6.9, 5.0, 5.7, 4.9, 6.7, 4.9, 5.7, 6.0, 4.8, 4.9, 5.6, 5.8, 6.1, 6.4, 5.6, 5.1, 5.6, 6.1, 5.6, 5.5, 4.8, 5.4, 5.6, 5.1, 5.1, 5.9, 5.7, 5.2, 5.0, 5.2, 5.4, 5.1]}], \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"species=virginica<br>%{xaxis.title.text}=%{x}<br>%{yaxis.title.text}=%{y}\", \"legendgroup\": \"species=virginica\", \"marker\": {\"color\": \"#00cc96\", \"symbol\": \"circle\"}, \"name\": \"species=virginica\", \"showlegend\": true, \"type\": \"splom\"}],\n",
              "                        {\"dragmode\": \"select\", \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8ed00c9b-9c16-4568-908f-797483a225ab');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpMQ-0rpF_Jm"
      },
      "source": [
        "# **Two-Class Averaged Perceptron**\n",
        "\n",
        "\n",
        "The averaged perceptron method is an early and very simple version of a neural network. In this approach, inputs are classified into several possible outputs based on a linear function, and then combined with a set of weights that are derived from the feature vectorâ€”hence the name \"perceptron.\n",
        "\n",
        "Specify how you want the model to be trained, by setting the Create trainer mode option.\n",
        "Here we expand our tiny linear model into a Perceptron below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bxTlDsf064C"
      },
      "source": [
        "## Optimisation steps to fit the model parameters to the data. \n",
        "\n",
        "Search parameters from an infinite hypothesis family to 1000 iterations!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxouoW_XxxbV"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,y,test_size=0.20,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5GK39RMSs4w"
      },
      "source": [
        "1. Set the Parameter Range: If you are not sure of the best parameters, find the optimal parameters by specifying multiple values and using the Tune Model Hyperparameters module to find the optimal configuration. The trainer iterates over multiple combinations of the settings you provided and determines the combination of values that produces the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkBe7ptCbQnA"
      },
      "source": [
        "max_iter = 1000\n",
        "class MyPerceptron:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        The constructor method of an object.\n",
        "        \"\"\"\n",
        "        self.h = np.array([0, 1, 0], dtype=np.float)\n",
        "\n",
        "\n",
        "    def compute_linear_score_with_(self, X, h):\n",
        "        \"\"\"\n",
        "        Compute the linear function\n",
        "        s[i] = <h, X[i]> + bias, <., .> represents inner product\n",
        "        \"\"\"\n",
        "        s = None\n",
        "        # insert your code here\n",
        "        # HINT: the *last* element in an array is represented as a[-1]\n",
        "        s = (X * h[:-1]).sum(axis=1) + h[-1]\n",
        "        return s\n",
        "\n",
        "    def predict_with_(self, X, h):\n",
        "        # return 0/1 according to the linear score\n",
        "        return np.sign(self.compute_linear_score_with_(X, h)).astype(np.int)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.predict_with_(X, self.h)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        :param X: training samples -- observed attribute values\n",
        "        :param y: the known answer for each sample\n",
        "\n",
        "        NOTE: now the \"loss\" has been encoded. You can try a customised one!\n",
        "        \"\"\"\n",
        "       \n",
        "        ii = 0\n",
        "        while True:\n",
        "            predicted = self.predict_with_(X, self.h)\n",
        "           \n",
        "            error_indexes = np.nonzero(predicted != y)[0]\n",
        "            if len(error_indexes) > 0:\n",
        "                i = error_indexes[np.random.randint(len(error_indexes))]\n",
        "                self.h[:-1] += X[i] * float(y[i])\n",
        "                \n",
        "                self.h[-1] += float(y[i])\n",
        "                \n",
        "                print(f\"{ii} Train errors: {len(error_indexes)}\")\n",
        "              \n",
        "            else: \n",
        "                break \n",
        "            ii += 1\n",
        "            if ii>=max_iter:\n",
        "                break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQGE9i0wbsc3",
        "outputId": "d68cbe3b-36bd-47d1-b035-3e3a1433ab58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "my_model = MyPerceptron() # initiate an object\n",
        "my_model.fit(simple_X_train, simple_y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train errors: 35\n",
            "1 Train errors: 35\n",
            "2 Train errors: 35\n",
            "3 Train errors: 35\n",
            "4 Train errors: 35\n",
            "5 Train errors: 35\n",
            "6 Train errors: 35\n",
            "7 Train errors: 35\n",
            "8 Train errors: 35\n",
            "9 Train errors: 35\n",
            "10 Train errors: 35\n",
            "11 Train errors: 35\n",
            "12 Train errors: 35\n",
            "13 Train errors: 35\n",
            "14 Train errors: 35\n",
            "15 Train errors: 35\n",
            "16 Train errors: 35\n",
            "17 Train errors: 35\n",
            "18 Train errors: 35\n",
            "19 Train errors: 35\n",
            "20 Train errors: 35\n",
            "21 Train errors: 35\n",
            "22 Train errors: 35\n",
            "23 Train errors: 35\n",
            "24 Train errors: 35\n",
            "25 Train errors: 35\n",
            "26 Train errors: 35\n",
            "27 Train errors: 35\n",
            "28 Train errors: 35\n",
            "29 Train errors: 35\n",
            "30 Train errors: 35\n",
            "31 Train errors: 35\n",
            "32 Train errors: 35\n",
            "33 Train errors: 35\n",
            "34 Train errors: 35\n",
            "35 Train errors: 35\n",
            "36 Train errors: 35\n",
            "37 Train errors: 35\n",
            "38 Train errors: 35\n",
            "39 Train errors: 35\n",
            "40 Train errors: 35\n",
            "41 Train errors: 35\n",
            "42 Train errors: 35\n",
            "43 Train errors: 35\n",
            "44 Train errors: 35\n",
            "45 Train errors: 35\n",
            "46 Train errors: 35\n",
            "47 Train errors: 35\n",
            "48 Train errors: 35\n",
            "49 Train errors: 35\n",
            "50 Train errors: 35\n",
            "51 Train errors: 35\n",
            "52 Train errors: 35\n",
            "53 Train errors: 35\n",
            "54 Train errors: 35\n",
            "55 Train errors: 35\n",
            "56 Train errors: 35\n",
            "57 Train errors: 35\n",
            "58 Train errors: 35\n",
            "59 Train errors: 35\n",
            "60 Train errors: 35\n",
            "61 Train errors: 35\n",
            "62 Train errors: 35\n",
            "63 Train errors: 35\n",
            "64 Train errors: 35\n",
            "65 Train errors: 35\n",
            "66 Train errors: 35\n",
            "67 Train errors: 35\n",
            "68 Train errors: 35\n",
            "69 Train errors: 35\n",
            "70 Train errors: 35\n",
            "71 Train errors: 35\n",
            "72 Train errors: 35\n",
            "73 Train errors: 35\n",
            "74 Train errors: 35\n",
            "75 Train errors: 35\n",
            "76 Train errors: 35\n",
            "77 Train errors: 35\n",
            "78 Train errors: 35\n",
            "79 Train errors: 35\n",
            "80 Train errors: 35\n",
            "81 Train errors: 35\n",
            "82 Train errors: 35\n",
            "83 Train errors: 35\n",
            "84 Train errors: 35\n",
            "85 Train errors: 35\n",
            "86 Train errors: 35\n",
            "87 Train errors: 35\n",
            "88 Train errors: 35\n",
            "89 Train errors: 35\n",
            "90 Train errors: 35\n",
            "91 Train errors: 35\n",
            "92 Train errors: 35\n",
            "93 Train errors: 35\n",
            "94 Train errors: 35\n",
            "95 Train errors: 35\n",
            "96 Train errors: 35\n",
            "97 Train errors: 35\n",
            "98 Train errors: 35\n",
            "99 Train errors: 35\n",
            "100 Train errors: 35\n",
            "101 Train errors: 35\n",
            "102 Train errors: 35\n",
            "103 Train errors: 35\n",
            "104 Train errors: 35\n",
            "105 Train errors: 35\n",
            "106 Train errors: 35\n",
            "107 Train errors: 35\n",
            "108 Train errors: 35\n",
            "109 Train errors: 35\n",
            "110 Train errors: 35\n",
            "111 Train errors: 35\n",
            "112 Train errors: 35\n",
            "113 Train errors: 35\n",
            "114 Train errors: 35\n",
            "115 Train errors: 35\n",
            "116 Train errors: 35\n",
            "117 Train errors: 35\n",
            "118 Train errors: 35\n",
            "119 Train errors: 35\n",
            "120 Train errors: 35\n",
            "121 Train errors: 35\n",
            "122 Train errors: 35\n",
            "123 Train errors: 35\n",
            "124 Train errors: 35\n",
            "125 Train errors: 35\n",
            "126 Train errors: 35\n",
            "127 Train errors: 35\n",
            "128 Train errors: 35\n",
            "129 Train errors: 35\n",
            "130 Train errors: 35\n",
            "131 Train errors: 35\n",
            "132 Train errors: 35\n",
            "133 Train errors: 35\n",
            "134 Train errors: 35\n",
            "135 Train errors: 35\n",
            "136 Train errors: 35\n",
            "137 Train errors: 35\n",
            "138 Train errors: 35\n",
            "139 Train errors: 35\n",
            "140 Train errors: 35\n",
            "141 Train errors: 35\n",
            "142 Train errors: 35\n",
            "143 Train errors: 35\n",
            "144 Train errors: 35\n",
            "145 Train errors: 35\n",
            "146 Train errors: 35\n",
            "147 Train errors: 35\n",
            "148 Train errors: 35\n",
            "149 Train errors: 35\n",
            "150 Train errors: 35\n",
            "151 Train errors: 35\n",
            "152 Train errors: 35\n",
            "153 Train errors: 35\n",
            "154 Train errors: 35\n",
            "155 Train errors: 35\n",
            "156 Train errors: 35\n",
            "157 Train errors: 35\n",
            "158 Train errors: 35\n",
            "159 Train errors: 35\n",
            "160 Train errors: 35\n",
            "161 Train errors: 35\n",
            "162 Train errors: 35\n",
            "163 Train errors: 35\n",
            "164 Train errors: 35\n",
            "165 Train errors: 35\n",
            "166 Train errors: 35\n",
            "167 Train errors: 35\n",
            "168 Train errors: 35\n",
            "169 Train errors: 35\n",
            "170 Train errors: 35\n",
            "171 Train errors: 35\n",
            "172 Train errors: 35\n",
            "173 Train errors: 35\n",
            "174 Train errors: 35\n",
            "175 Train errors: 35\n",
            "176 Train errors: 35\n",
            "177 Train errors: 35\n",
            "178 Train errors: 35\n",
            "179 Train errors: 35\n",
            "180 Train errors: 35\n",
            "181 Train errors: 35\n",
            "182 Train errors: 35\n",
            "183 Train errors: 35\n",
            "184 Train errors: 35\n",
            "185 Train errors: 35\n",
            "186 Train errors: 35\n",
            "187 Train errors: 35\n",
            "188 Train errors: 35\n",
            "189 Train errors: 35\n",
            "190 Train errors: 35\n",
            "191 Train errors: 35\n",
            "192 Train errors: 35\n",
            "193 Train errors: 35\n",
            "194 Train errors: 35\n",
            "195 Train errors: 35\n",
            "196 Train errors: 35\n",
            "197 Train errors: 35\n",
            "198 Train errors: 35\n",
            "199 Train errors: 35\n",
            "200 Train errors: 35\n",
            "201 Train errors: 35\n",
            "202 Train errors: 35\n",
            "203 Train errors: 35\n",
            "204 Train errors: 35\n",
            "205 Train errors: 35\n",
            "206 Train errors: 35\n",
            "207 Train errors: 35\n",
            "208 Train errors: 35\n",
            "209 Train errors: 35\n",
            "210 Train errors: 35\n",
            "211 Train errors: 35\n",
            "212 Train errors: 35\n",
            "213 Train errors: 35\n",
            "214 Train errors: 35\n",
            "215 Train errors: 35\n",
            "216 Train errors: 35\n",
            "217 Train errors: 35\n",
            "218 Train errors: 35\n",
            "219 Train errors: 35\n",
            "220 Train errors: 35\n",
            "221 Train errors: 35\n",
            "222 Train errors: 35\n",
            "223 Train errors: 35\n",
            "224 Train errors: 35\n",
            "225 Train errors: 35\n",
            "226 Train errors: 35\n",
            "227 Train errors: 35\n",
            "228 Train errors: 35\n",
            "229 Train errors: 35\n",
            "230 Train errors: 35\n",
            "231 Train errors: 35\n",
            "232 Train errors: 35\n",
            "233 Train errors: 35\n",
            "234 Train errors: 35\n",
            "235 Train errors: 35\n",
            "236 Train errors: 35\n",
            "237 Train errors: 35\n",
            "238 Train errors: 35\n",
            "239 Train errors: 35\n",
            "240 Train errors: 35\n",
            "241 Train errors: 35\n",
            "242 Train errors: 35\n",
            "243 Train errors: 35\n",
            "244 Train errors: 35\n",
            "245 Train errors: 35\n",
            "246 Train errors: 35\n",
            "247 Train errors: 35\n",
            "248 Train errors: 35\n",
            "249 Train errors: 35\n",
            "250 Train errors: 35\n",
            "251 Train errors: 35\n",
            "252 Train errors: 35\n",
            "253 Train errors: 35\n",
            "254 Train errors: 35\n",
            "255 Train errors: 35\n",
            "256 Train errors: 35\n",
            "257 Train errors: 35\n",
            "258 Train errors: 35\n",
            "259 Train errors: 35\n",
            "260 Train errors: 35\n",
            "261 Train errors: 35\n",
            "262 Train errors: 35\n",
            "263 Train errors: 35\n",
            "264 Train errors: 35\n",
            "265 Train errors: 35\n",
            "266 Train errors: 35\n",
            "267 Train errors: 35\n",
            "268 Train errors: 35\n",
            "269 Train errors: 35\n",
            "270 Train errors: 35\n",
            "271 Train errors: 35\n",
            "272 Train errors: 35\n",
            "273 Train errors: 35\n",
            "274 Train errors: 35\n",
            "275 Train errors: 35\n",
            "276 Train errors: 35\n",
            "277 Train errors: 35\n",
            "278 Train errors: 35\n",
            "279 Train errors: 35\n",
            "280 Train errors: 35\n",
            "281 Train errors: 35\n",
            "282 Train errors: 35\n",
            "283 Train errors: 35\n",
            "284 Train errors: 35\n",
            "285 Train errors: 35\n",
            "286 Train errors: 35\n",
            "287 Train errors: 35\n",
            "288 Train errors: 35\n",
            "289 Train errors: 35\n",
            "290 Train errors: 35\n",
            "291 Train errors: 35\n",
            "292 Train errors: 35\n",
            "293 Train errors: 35\n",
            "294 Train errors: 35\n",
            "295 Train errors: 35\n",
            "296 Train errors: 35\n",
            "297 Train errors: 35\n",
            "298 Train errors: 35\n",
            "299 Train errors: 35\n",
            "300 Train errors: 35\n",
            "301 Train errors: 35\n",
            "302 Train errors: 35\n",
            "303 Train errors: 35\n",
            "304 Train errors: 35\n",
            "305 Train errors: 35\n",
            "306 Train errors: 35\n",
            "307 Train errors: 35\n",
            "308 Train errors: 35\n",
            "309 Train errors: 35\n",
            "310 Train errors: 35\n",
            "311 Train errors: 35\n",
            "312 Train errors: 35\n",
            "313 Train errors: 35\n",
            "314 Train errors: 35\n",
            "315 Train errors: 35\n",
            "316 Train errors: 35\n",
            "317 Train errors: 35\n",
            "318 Train errors: 35\n",
            "319 Train errors: 35\n",
            "320 Train errors: 35\n",
            "321 Train errors: 35\n",
            "322 Train errors: 35\n",
            "323 Train errors: 35\n",
            "324 Train errors: 35\n",
            "325 Train errors: 35\n",
            "326 Train errors: 35\n",
            "327 Train errors: 35\n",
            "328 Train errors: 35\n",
            "329 Train errors: 35\n",
            "330 Train errors: 35\n",
            "331 Train errors: 35\n",
            "332 Train errors: 35\n",
            "333 Train errors: 35\n",
            "334 Train errors: 35\n",
            "335 Train errors: 35\n",
            "336 Train errors: 35\n",
            "337 Train errors: 35\n",
            "338 Train errors: 35\n",
            "339 Train errors: 35\n",
            "340 Train errors: 35\n",
            "341 Train errors: 35\n",
            "342 Train errors: 35\n",
            "343 Train errors: 35\n",
            "344 Train errors: 35\n",
            "345 Train errors: 35\n",
            "346 Train errors: 35\n",
            "347 Train errors: 35\n",
            "348 Train errors: 35\n",
            "349 Train errors: 35\n",
            "350 Train errors: 35\n",
            "351 Train errors: 35\n",
            "352 Train errors: 35\n",
            "353 Train errors: 35\n",
            "354 Train errors: 35\n",
            "355 Train errors: 35\n",
            "356 Train errors: 35\n",
            "357 Train errors: 35\n",
            "358 Train errors: 35\n",
            "359 Train errors: 35\n",
            "360 Train errors: 35\n",
            "361 Train errors: 35\n",
            "362 Train errors: 35\n",
            "363 Train errors: 35\n",
            "364 Train errors: 35\n",
            "365 Train errors: 35\n",
            "366 Train errors: 35\n",
            "367 Train errors: 35\n",
            "368 Train errors: 35\n",
            "369 Train errors: 35\n",
            "370 Train errors: 35\n",
            "371 Train errors: 35\n",
            "372 Train errors: 35\n",
            "373 Train errors: 35\n",
            "374 Train errors: 35\n",
            "375 Train errors: 35\n",
            "376 Train errors: 35\n",
            "377 Train errors: 35\n",
            "378 Train errors: 35\n",
            "379 Train errors: 35\n",
            "380 Train errors: 35\n",
            "381 Train errors: 35\n",
            "382 Train errors: 35\n",
            "383 Train errors: 35\n",
            "384 Train errors: 35\n",
            "385 Train errors: 35\n",
            "386 Train errors: 35\n",
            "387 Train errors: 35\n",
            "388 Train errors: 35\n",
            "389 Train errors: 35\n",
            "390 Train errors: 35\n",
            "391 Train errors: 35\n",
            "392 Train errors: 35\n",
            "393 Train errors: 35\n",
            "394 Train errors: 35\n",
            "395 Train errors: 35\n",
            "396 Train errors: 35\n",
            "397 Train errors: 35\n",
            "398 Train errors: 35\n",
            "399 Train errors: 35\n",
            "400 Train errors: 35\n",
            "401 Train errors: 35\n",
            "402 Train errors: 35\n",
            "403 Train errors: 35\n",
            "404 Train errors: 35\n",
            "405 Train errors: 35\n",
            "406 Train errors: 35\n",
            "407 Train errors: 35\n",
            "408 Train errors: 35\n",
            "409 Train errors: 35\n",
            "410 Train errors: 35\n",
            "411 Train errors: 35\n",
            "412 Train errors: 35\n",
            "413 Train errors: 35\n",
            "414 Train errors: 35\n",
            "415 Train errors: 35\n",
            "416 Train errors: 35\n",
            "417 Train errors: 35\n",
            "418 Train errors: 35\n",
            "419 Train errors: 35\n",
            "420 Train errors: 35\n",
            "421 Train errors: 35\n",
            "422 Train errors: 35\n",
            "423 Train errors: 35\n",
            "424 Train errors: 35\n",
            "425 Train errors: 35\n",
            "426 Train errors: 35\n",
            "427 Train errors: 35\n",
            "428 Train errors: 35\n",
            "429 Train errors: 35\n",
            "430 Train errors: 35\n",
            "431 Train errors: 35\n",
            "432 Train errors: 35\n",
            "433 Train errors: 35\n",
            "434 Train errors: 35\n",
            "435 Train errors: 35\n",
            "436 Train errors: 35\n",
            "437 Train errors: 35\n",
            "438 Train errors: 35\n",
            "439 Train errors: 35\n",
            "440 Train errors: 35\n",
            "441 Train errors: 35\n",
            "442 Train errors: 35\n",
            "443 Train errors: 35\n",
            "444 Train errors: 35\n",
            "445 Train errors: 35\n",
            "446 Train errors: 35\n",
            "447 Train errors: 35\n",
            "448 Train errors: 35\n",
            "449 Train errors: 35\n",
            "450 Train errors: 35\n",
            "451 Train errors: 35\n",
            "452 Train errors: 35\n",
            "453 Train errors: 35\n",
            "454 Train errors: 35\n",
            "455 Train errors: 35\n",
            "456 Train errors: 35\n",
            "457 Train errors: 35\n",
            "458 Train errors: 35\n",
            "459 Train errors: 35\n",
            "460 Train errors: 35\n",
            "461 Train errors: 35\n",
            "462 Train errors: 35\n",
            "463 Train errors: 35\n",
            "464 Train errors: 35\n",
            "465 Train errors: 35\n",
            "466 Train errors: 35\n",
            "467 Train errors: 35\n",
            "468 Train errors: 35\n",
            "469 Train errors: 35\n",
            "470 Train errors: 35\n",
            "471 Train errors: 35\n",
            "472 Train errors: 35\n",
            "473 Train errors: 35\n",
            "474 Train errors: 35\n",
            "475 Train errors: 35\n",
            "476 Train errors: 35\n",
            "477 Train errors: 35\n",
            "478 Train errors: 35\n",
            "479 Train errors: 35\n",
            "480 Train errors: 35\n",
            "481 Train errors: 35\n",
            "482 Train errors: 35\n",
            "483 Train errors: 35\n",
            "484 Train errors: 35\n",
            "485 Train errors: 35\n",
            "486 Train errors: 35\n",
            "487 Train errors: 35\n",
            "488 Train errors: 35\n",
            "489 Train errors: 35\n",
            "490 Train errors: 35\n",
            "491 Train errors: 35\n",
            "492 Train errors: 35\n",
            "493 Train errors: 35\n",
            "494 Train errors: 35\n",
            "495 Train errors: 35\n",
            "496 Train errors: 35\n",
            "497 Train errors: 35\n",
            "498 Train errors: 35\n",
            "499 Train errors: 35\n",
            "500 Train errors: 35\n",
            "501 Train errors: 35\n",
            "502 Train errors: 35\n",
            "503 Train errors: 35\n",
            "504 Train errors: 35\n",
            "505 Train errors: 35\n",
            "506 Train errors: 35\n",
            "507 Train errors: 35\n",
            "508 Train errors: 35\n",
            "509 Train errors: 35\n",
            "510 Train errors: 35\n",
            "511 Train errors: 35\n",
            "512 Train errors: 35\n",
            "513 Train errors: 35\n",
            "514 Train errors: 35\n",
            "515 Train errors: 35\n",
            "516 Train errors: 35\n",
            "517 Train errors: 35\n",
            "518 Train errors: 35\n",
            "519 Train errors: 35\n",
            "520 Train errors: 35\n",
            "521 Train errors: 35\n",
            "522 Train errors: 35\n",
            "523 Train errors: 35\n",
            "524 Train errors: 35\n",
            "525 Train errors: 35\n",
            "526 Train errors: 35\n",
            "527 Train errors: 35\n",
            "528 Train errors: 35\n",
            "529 Train errors: 35\n",
            "530 Train errors: 35\n",
            "531 Train errors: 35\n",
            "532 Train errors: 35\n",
            "533 Train errors: 35\n",
            "534 Train errors: 35\n",
            "535 Train errors: 35\n",
            "536 Train errors: 35\n",
            "537 Train errors: 35\n",
            "538 Train errors: 35\n",
            "539 Train errors: 35\n",
            "540 Train errors: 35\n",
            "541 Train errors: 35\n",
            "542 Train errors: 35\n",
            "543 Train errors: 35\n",
            "544 Train errors: 35\n",
            "545 Train errors: 35\n",
            "546 Train errors: 35\n",
            "547 Train errors: 35\n",
            "548 Train errors: 35\n",
            "549 Train errors: 35\n",
            "550 Train errors: 35\n",
            "551 Train errors: 35\n",
            "552 Train errors: 35\n",
            "553 Train errors: 35\n",
            "554 Train errors: 35\n",
            "555 Train errors: 35\n",
            "556 Train errors: 35\n",
            "557 Train errors: 35\n",
            "558 Train errors: 35\n",
            "559 Train errors: 35\n",
            "560 Train errors: 35\n",
            "561 Train errors: 35\n",
            "562 Train errors: 35\n",
            "563 Train errors: 35\n",
            "564 Train errors: 35\n",
            "565 Train errors: 35\n",
            "566 Train errors: 35\n",
            "567 Train errors: 35\n",
            "568 Train errors: 35\n",
            "569 Train errors: 35\n",
            "570 Train errors: 35\n",
            "571 Train errors: 35\n",
            "572 Train errors: 35\n",
            "573 Train errors: 35\n",
            "574 Train errors: 35\n",
            "575 Train errors: 35\n",
            "576 Train errors: 35\n",
            "577 Train errors: 35\n",
            "578 Train errors: 35\n",
            "579 Train errors: 35\n",
            "580 Train errors: 35\n",
            "581 Train errors: 35\n",
            "582 Train errors: 35\n",
            "583 Train errors: 35\n",
            "584 Train errors: 35\n",
            "585 Train errors: 35\n",
            "586 Train errors: 35\n",
            "587 Train errors: 35\n",
            "588 Train errors: 35\n",
            "589 Train errors: 35\n",
            "590 Train errors: 35\n",
            "591 Train errors: 35\n",
            "592 Train errors: 35\n",
            "593 Train errors: 35\n",
            "594 Train errors: 35\n",
            "595 Train errors: 35\n",
            "596 Train errors: 35\n",
            "597 Train errors: 35\n",
            "598 Train errors: 35\n",
            "599 Train errors: 35\n",
            "600 Train errors: 35\n",
            "601 Train errors: 35\n",
            "602 Train errors: 35\n",
            "603 Train errors: 35\n",
            "604 Train errors: 35\n",
            "605 Train errors: 35\n",
            "606 Train errors: 35\n",
            "607 Train errors: 35\n",
            "608 Train errors: 35\n",
            "609 Train errors: 35\n",
            "610 Train errors: 35\n",
            "611 Train errors: 35\n",
            "612 Train errors: 35\n",
            "613 Train errors: 35\n",
            "614 Train errors: 35\n",
            "615 Train errors: 35\n",
            "616 Train errors: 35\n",
            "617 Train errors: 35\n",
            "618 Train errors: 35\n",
            "619 Train errors: 35\n",
            "620 Train errors: 35\n",
            "621 Train errors: 35\n",
            "622 Train errors: 35\n",
            "623 Train errors: 35\n",
            "624 Train errors: 35\n",
            "625 Train errors: 35\n",
            "626 Train errors: 35\n",
            "627 Train errors: 35\n",
            "628 Train errors: 35\n",
            "629 Train errors: 35\n",
            "630 Train errors: 35\n",
            "631 Train errors: 35\n",
            "632 Train errors: 35\n",
            "633 Train errors: 35\n",
            "634 Train errors: 35\n",
            "635 Train errors: 35\n",
            "636 Train errors: 35\n",
            "637 Train errors: 35\n",
            "638 Train errors: 35\n",
            "639 Train errors: 35\n",
            "640 Train errors: 35\n",
            "641 Train errors: 35\n",
            "642 Train errors: 35\n",
            "643 Train errors: 35\n",
            "644 Train errors: 35\n",
            "645 Train errors: 35\n",
            "646 Train errors: 35\n",
            "647 Train errors: 35\n",
            "648 Train errors: 35\n",
            "649 Train errors: 35\n",
            "650 Train errors: 35\n",
            "651 Train errors: 35\n",
            "652 Train errors: 35\n",
            "653 Train errors: 35\n",
            "654 Train errors: 35\n",
            "655 Train errors: 35\n",
            "656 Train errors: 35\n",
            "657 Train errors: 35\n",
            "658 Train errors: 35\n",
            "659 Train errors: 35\n",
            "660 Train errors: 35\n",
            "661 Train errors: 35\n",
            "662 Train errors: 35\n",
            "663 Train errors: 35\n",
            "664 Train errors: 35\n",
            "665 Train errors: 35\n",
            "666 Train errors: 35\n",
            "667 Train errors: 35\n",
            "668 Train errors: 35\n",
            "669 Train errors: 35\n",
            "670 Train errors: 35\n",
            "671 Train errors: 35\n",
            "672 Train errors: 35\n",
            "673 Train errors: 35\n",
            "674 Train errors: 35\n",
            "675 Train errors: 35\n",
            "676 Train errors: 35\n",
            "677 Train errors: 35\n",
            "678 Train errors: 35\n",
            "679 Train errors: 35\n",
            "680 Train errors: 35\n",
            "681 Train errors: 35\n",
            "682 Train errors: 35\n",
            "683 Train errors: 35\n",
            "684 Train errors: 35\n",
            "685 Train errors: 35\n",
            "686 Train errors: 35\n",
            "687 Train errors: 35\n",
            "688 Train errors: 35\n",
            "689 Train errors: 35\n",
            "690 Train errors: 35\n",
            "691 Train errors: 35\n",
            "692 Train errors: 35\n",
            "693 Train errors: 35\n",
            "694 Train errors: 35\n",
            "695 Train errors: 35\n",
            "696 Train errors: 35\n",
            "697 Train errors: 35\n",
            "698 Train errors: 35\n",
            "699 Train errors: 35\n",
            "700 Train errors: 35\n",
            "701 Train errors: 35\n",
            "702 Train errors: 35\n",
            "703 Train errors: 35\n",
            "704 Train errors: 35\n",
            "705 Train errors: 35\n",
            "706 Train errors: 35\n",
            "707 Train errors: 35\n",
            "708 Train errors: 35\n",
            "709 Train errors: 35\n",
            "710 Train errors: 35\n",
            "711 Train errors: 35\n",
            "712 Train errors: 35\n",
            "713 Train errors: 35\n",
            "714 Train errors: 35\n",
            "715 Train errors: 35\n",
            "716 Train errors: 35\n",
            "717 Train errors: 35\n",
            "718 Train errors: 35\n",
            "719 Train errors: 35\n",
            "720 Train errors: 35\n",
            "721 Train errors: 35\n",
            "722 Train errors: 35\n",
            "723 Train errors: 35\n",
            "724 Train errors: 35\n",
            "725 Train errors: 35\n",
            "726 Train errors: 35\n",
            "727 Train errors: 35\n",
            "728 Train errors: 35\n",
            "729 Train errors: 35\n",
            "730 Train errors: 35\n",
            "731 Train errors: 35\n",
            "732 Train errors: 35\n",
            "733 Train errors: 35\n",
            "734 Train errors: 35\n",
            "735 Train errors: 35\n",
            "736 Train errors: 35\n",
            "737 Train errors: 35\n",
            "738 Train errors: 35\n",
            "739 Train errors: 35\n",
            "740 Train errors: 35\n",
            "741 Train errors: 35\n",
            "742 Train errors: 35\n",
            "743 Train errors: 35\n",
            "744 Train errors: 35\n",
            "745 Train errors: 35\n",
            "746 Train errors: 35\n",
            "747 Train errors: 35\n",
            "748 Train errors: 35\n",
            "749 Train errors: 35\n",
            "750 Train errors: 35\n",
            "751 Train errors: 35\n",
            "752 Train errors: 35\n",
            "753 Train errors: 35\n",
            "754 Train errors: 35\n",
            "755 Train errors: 35\n",
            "756 Train errors: 35\n",
            "757 Train errors: 35\n",
            "758 Train errors: 35\n",
            "759 Train errors: 35\n",
            "760 Train errors: 35\n",
            "761 Train errors: 35\n",
            "762 Train errors: 35\n",
            "763 Train errors: 35\n",
            "764 Train errors: 35\n",
            "765 Train errors: 35\n",
            "766 Train errors: 35\n",
            "767 Train errors: 35\n",
            "768 Train errors: 35\n",
            "769 Train errors: 35\n",
            "770 Train errors: 35\n",
            "771 Train errors: 35\n",
            "772 Train errors: 35\n",
            "773 Train errors: 35\n",
            "774 Train errors: 35\n",
            "775 Train errors: 35\n",
            "776 Train errors: 35\n",
            "777 Train errors: 35\n",
            "778 Train errors: 35\n",
            "779 Train errors: 35\n",
            "780 Train errors: 35\n",
            "781 Train errors: 35\n",
            "782 Train errors: 35\n",
            "783 Train errors: 35\n",
            "784 Train errors: 35\n",
            "785 Train errors: 35\n",
            "786 Train errors: 35\n",
            "787 Train errors: 35\n",
            "788 Train errors: 35\n",
            "789 Train errors: 35\n",
            "790 Train errors: 35\n",
            "791 Train errors: 35\n",
            "792 Train errors: 35\n",
            "793 Train errors: 35\n",
            "794 Train errors: 35\n",
            "795 Train errors: 35\n",
            "796 Train errors: 35\n",
            "797 Train errors: 35\n",
            "798 Train errors: 35\n",
            "799 Train errors: 35\n",
            "800 Train errors: 35\n",
            "801 Train errors: 35\n",
            "802 Train errors: 35\n",
            "803 Train errors: 35\n",
            "804 Train errors: 35\n",
            "805 Train errors: 35\n",
            "806 Train errors: 35\n",
            "807 Train errors: 35\n",
            "808 Train errors: 35\n",
            "809 Train errors: 35\n",
            "810 Train errors: 35\n",
            "811 Train errors: 35\n",
            "812 Train errors: 35\n",
            "813 Train errors: 35\n",
            "814 Train errors: 35\n",
            "815 Train errors: 35\n",
            "816 Train errors: 35\n",
            "817 Train errors: 35\n",
            "818 Train errors: 35\n",
            "819 Train errors: 35\n",
            "820 Train errors: 35\n",
            "821 Train errors: 35\n",
            "822 Train errors: 35\n",
            "823 Train errors: 35\n",
            "824 Train errors: 35\n",
            "825 Train errors: 35\n",
            "826 Train errors: 35\n",
            "827 Train errors: 35\n",
            "828 Train errors: 35\n",
            "829 Train errors: 35\n",
            "830 Train errors: 35\n",
            "831 Train errors: 35\n",
            "832 Train errors: 35\n",
            "833 Train errors: 35\n",
            "834 Train errors: 35\n",
            "835 Train errors: 35\n",
            "836 Train errors: 35\n",
            "837 Train errors: 35\n",
            "838 Train errors: 35\n",
            "839 Train errors: 35\n",
            "840 Train errors: 35\n",
            "841 Train errors: 35\n",
            "842 Train errors: 35\n",
            "843 Train errors: 35\n",
            "844 Train errors: 35\n",
            "845 Train errors: 35\n",
            "846 Train errors: 35\n",
            "847 Train errors: 35\n",
            "848 Train errors: 35\n",
            "849 Train errors: 35\n",
            "850 Train errors: 35\n",
            "851 Train errors: 35\n",
            "852 Train errors: 35\n",
            "853 Train errors: 35\n",
            "854 Train errors: 35\n",
            "855 Train errors: 35\n",
            "856 Train errors: 35\n",
            "857 Train errors: 35\n",
            "858 Train errors: 35\n",
            "859 Train errors: 35\n",
            "860 Train errors: 35\n",
            "861 Train errors: 35\n",
            "862 Train errors: 35\n",
            "863 Train errors: 35\n",
            "864 Train errors: 35\n",
            "865 Train errors: 35\n",
            "866 Train errors: 35\n",
            "867 Train errors: 35\n",
            "868 Train errors: 35\n",
            "869 Train errors: 35\n",
            "870 Train errors: 35\n",
            "871 Train errors: 35\n",
            "872 Train errors: 35\n",
            "873 Train errors: 35\n",
            "874 Train errors: 35\n",
            "875 Train errors: 35\n",
            "876 Train errors: 35\n",
            "877 Train errors: 35\n",
            "878 Train errors: 35\n",
            "879 Train errors: 35\n",
            "880 Train errors: 35\n",
            "881 Train errors: 35\n",
            "882 Train errors: 35\n",
            "883 Train errors: 35\n",
            "884 Train errors: 35\n",
            "885 Train errors: 35\n",
            "886 Train errors: 35\n",
            "887 Train errors: 35\n",
            "888 Train errors: 35\n",
            "889 Train errors: 35\n",
            "890 Train errors: 35\n",
            "891 Train errors: 35\n",
            "892 Train errors: 35\n",
            "893 Train errors: 35\n",
            "894 Train errors: 35\n",
            "895 Train errors: 35\n",
            "896 Train errors: 35\n",
            "897 Train errors: 35\n",
            "898 Train errors: 35\n",
            "899 Train errors: 35\n",
            "900 Train errors: 35\n",
            "901 Train errors: 35\n",
            "902 Train errors: 35\n",
            "903 Train errors: 35\n",
            "904 Train errors: 35\n",
            "905 Train errors: 35\n",
            "906 Train errors: 35\n",
            "907 Train errors: 35\n",
            "908 Train errors: 35\n",
            "909 Train errors: 35\n",
            "910 Train errors: 35\n",
            "911 Train errors: 35\n",
            "912 Train errors: 35\n",
            "913 Train errors: 35\n",
            "914 Train errors: 35\n",
            "915 Train errors: 35\n",
            "916 Train errors: 35\n",
            "917 Train errors: 35\n",
            "918 Train errors: 35\n",
            "919 Train errors: 35\n",
            "920 Train errors: 35\n",
            "921 Train errors: 35\n",
            "922 Train errors: 35\n",
            "923 Train errors: 35\n",
            "924 Train errors: 35\n",
            "925 Train errors: 35\n",
            "926 Train errors: 35\n",
            "927 Train errors: 35\n",
            "928 Train errors: 35\n",
            "929 Train errors: 35\n",
            "930 Train errors: 35\n",
            "931 Train errors: 35\n",
            "932 Train errors: 35\n",
            "933 Train errors: 35\n",
            "934 Train errors: 35\n",
            "935 Train errors: 35\n",
            "936 Train errors: 35\n",
            "937 Train errors: 35\n",
            "938 Train errors: 35\n",
            "939 Train errors: 35\n",
            "940 Train errors: 35\n",
            "941 Train errors: 35\n",
            "942 Train errors: 35\n",
            "943 Train errors: 35\n",
            "944 Train errors: 35\n",
            "945 Train errors: 35\n",
            "946 Train errors: 35\n",
            "947 Train errors: 35\n",
            "948 Train errors: 35\n",
            "949 Train errors: 35\n",
            "950 Train errors: 35\n",
            "951 Train errors: 35\n",
            "952 Train errors: 35\n",
            "953 Train errors: 35\n",
            "954 Train errors: 35\n",
            "955 Train errors: 35\n",
            "956 Train errors: 35\n",
            "957 Train errors: 35\n",
            "958 Train errors: 35\n",
            "959 Train errors: 35\n",
            "960 Train errors: 35\n",
            "961 Train errors: 35\n",
            "962 Train errors: 35\n",
            "963 Train errors: 35\n",
            "964 Train errors: 35\n",
            "965 Train errors: 35\n",
            "966 Train errors: 35\n",
            "967 Train errors: 35\n",
            "968 Train errors: 35\n",
            "969 Train errors: 35\n",
            "970 Train errors: 35\n",
            "971 Train errors: 35\n",
            "972 Train errors: 35\n",
            "973 Train errors: 35\n",
            "974 Train errors: 35\n",
            "975 Train errors: 35\n",
            "976 Train errors: 35\n",
            "977 Train errors: 35\n",
            "978 Train errors: 35\n",
            "979 Train errors: 35\n",
            "980 Train errors: 35\n",
            "981 Train errors: 35\n",
            "982 Train errors: 35\n",
            "983 Train errors: 35\n",
            "984 Train errors: 35\n",
            "985 Train errors: 35\n",
            "986 Train errors: 35\n",
            "987 Train errors: 35\n",
            "988 Train errors: 35\n",
            "989 Train errors: 35\n",
            "990 Train errors: 35\n",
            "991 Train errors: 35\n",
            "992 Train errors: 35\n",
            "993 Train errors: 35\n",
            "994 Train errors: 35\n",
            "995 Train errors: 35\n",
            "996 Train errors: 35\n",
            "997 Train errors: 35\n",
            "998 Train errors: 35\n",
            "999 Train errors: 35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RWnNnY1iKuE"
      },
      "source": [
        "max_iter = 1000\n",
        "class Perceptron:\n",
        "    def __init__(self):\n",
        "        self.h = np.array([0, 1, 0], dtype=np.float)\n",
        "\n",
        "\n",
        "    def compute_linear_score_with_(self, X, h):\n",
        "        s = None\n",
        "        s = (X * h[:-1]).sum(axis=1) + h[-1]\n",
        "        return s\n",
        "\n",
        "    def predict_with_(self, X, h):\n",
        "\n",
        "        return np.sign(self.compute_linear_score_with_(X, h)).astype(np.int)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.predict_with_(X, self.h)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        :param X: training samples -- observed attribute values\n",
        "        :param y: the known answer for each sample\n",
        "\n",
        "        NOTE: now the \"loss\" has been encoded. You can try a customised one!\n",
        "        \"\"\"\n",
        "        # Follow the tutorial of perpectron training\n",
        "        ii = 0\n",
        "        while True:\n",
        "            predicted = self.predict_with_(X, self.h)\n",
        "            error_indexes = np.nonzero(predicted != y)[0]\n",
        "            # `nonzero` returns the indexes for multiple dimension array,\n",
        "            # Here only the indexes of the first (and only) dimension is \n",
        "            # concerned, therefore the [0]\n",
        "\n",
        "            if len(error_indexes) > 0:\n",
        "                i = error_indexes[np.random.randint(len(error_indexes))]\n",
        "                self.h[:-1] += X[i] * float(y[i])\n",
        "                # To update the weights\n",
        "                self.h[-1] += float(y[i])\n",
        "                # To update the b-bias\n",
        "                #   This is equivalent to using the homogeneous representation\n",
        "                #   of x, where the last element is one\n",
        "                print(f\"{ii} Train errors: {len(error_indexes)}\")\n",
        "               # ii += 1\n",
        "            else: \n",
        "                break \n",
        "            ii += 1\n",
        "            if ii>=max_iter:\n",
        "                break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H53O4jxLA-QN",
        "outputId": "91f66a8f-9f0d-48f4-90b4-9b27373fda68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "        self.l1 = nn.Linear(4, 16)\n",
        "        self.l2 = nn.Linear(16, 1)\n",
        "\n",
        "nn = MyNet()\n",
        "a  = 0\n",
        "for p in nn.parameters():\n",
        "    a += p.numel()\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_lQunaZOBIa"
      },
      "source": [
        "Take only 2 classes 0. Setosa, 1 = versicolor, 2 = virginica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTFrtVzbPPKR"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30,random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grosfW0eNevW"
      },
      "source": [
        "Make a constant 1 attribute = homogenous variable list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsKFh4F9Na4e"
      },
      "source": [
        "ons_ = np.ones((X_train.shape[0],1))\n",
        "X_train_homo = np.concatenate([X_train, ons_], axis = 1)\n",
        "ons_ = np.ones((X_test.shape[0],1))\n",
        "X_test_homo = np.concatenate([X_test, ons_], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk3xTI0APrBU",
        "outputId": "60a24b50-3777-4e12-bdd0-4728c551f1de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "type(y_train), type(X_train_homo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, numpy.ndarray)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCcixjVWQeNp"
      },
      "source": [
        "W is a 5-vector \n",
        "X is a n x 5 array, representing the data.\n",
        "hval is a h-value, errors made on samples, h is always +/- by 1 detemined by a]]] "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvq-2--xS63T"
      },
      "source": [
        "def perceptron_predict(W, X):\n",
        "  hval = (W * X).sum(axis=1)\n",
        "  pred = np.sign(hval)\n",
        "  return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knXYsxWVTIUj",
        "outputId": "88068c39-7aed-45ea-d725-73f154b08bd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "W = np.array([0.1, -0.5, 3, -2, -10])\n",
        "print(perceptron_predict(W, X_train_homo))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1.\n",
            " -1. -1.  1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1.  1. -1.  1.  1. -1.\n",
            " -1. -1.  1.  1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1.  1. -1. -1.  1.\n",
            "  1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1.  1.  1. -1. -1.  1.\n",
            " -1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1.  1. -1.  1.  1. -1.  1.  1.\n",
            " -1.  1. -1.  1.  1. -1. -1.  1. -1.  1. -1. -1. -1.  1.  1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRWSbi27eNan"
      },
      "source": [
        "To find out where the predictin is correct or not!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqfewIbPnd2L"
      },
      "source": [
        "class MyPerceptron:\n",
        "  def __init__(self):\n",
        "      self.W = np.array([0.1, -0.5, 3, -2])\n",
        "      self.b = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a23wUb1AQIio",
        "outputId": "c354d064-68a1-45b2-c536-411b8ec1f647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "max_iterations = 1000\n",
        " \n",
        "def perceptron_predict(W, X):\n",
        "  hval = (W * X).sum(axis=1)\n",
        "  pred = np.sign(hval)\n",
        "  return pred\n",
        " \n",
        "  W = np.array([0.1, -0.5, 3, -2, -10])\n",
        " \n",
        "  while True:\n",
        "      pred = perceptron_predict(W, X_train_homo)\n",
        "      is_pred_corr = y_train == pred\n",
        "      is_pred_wrong = np.logical_not(is_pred_corr)\n",
        "      error_indexes = np.nonzero(is_pred_wrong)[0]\n",
        "      accu_train = np.count_nonzero(is_pred_corr) / y_train.size\n",
        "      print(f\"Training Accuracy {accu_train}\")\n",
        "      \n",
        "      pred_valid = perceptron_predict(W, X_test_homo)\n",
        "      accu_valid = np.count_nonzero(pred_valid == y_test) / y_test.size\n",
        "      print(f\"Validation Accuracy {accu_valid}\")\n",
        " \n",
        "      if len(error_indexes) > 0:\n",
        "            next_i = error_indexes[0]\n",
        "            W_update = X_train_homo[next_i] * y_train[next_i]\n",
        "            W += W_update\n",
        "      else: \n",
        "           break \n",
        "      ii += 1\n",
        "            \n",
        "      if ii>=max_iter:\n",
        "            break\n",
        "\n",
        "\n",
        " \n",
        "pred = perceptron_predict (W, X_train_homo)\n",
        " \n",
        "is_pred_corr = y_train.size\n",
        " \n",
        "print(is_pred_corr)\n",
        "print(np.nonzero(is_pred_corr))\n",
        "np.count_nonzero(y_train == pred) /y_train.size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105\n",
            "(array([0]),)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38095238095238093"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVLV_uG9YoTF",
        "outputId": "710aac9b-7106-4772-d1f4-0152f9ee8049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "pred_valid = my_model.predict(simple_X_valid)\n",
        "valid_corr_num = (pred_valid == simple_y_valid).sum()\n",
        "print(\"Valid accu\", valid_corr_num / len(simple_y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valid accu 0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOZkOM78gYVZ",
        "outputId": "09bee71f-10ac-4a71-aaae-ae6b057c87dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "pred = perceptron_predict(W, X_train_homo)\n",
        "is_pred_corr = y_train == pred\n",
        "is_pred_wrong = np.logical_not(is_pred_corr)\n",
        "error_indexes = np.nonzero(is_pred_wrong)[0]\n",
        "#find out where the prediction is INCORRECT\n",
        "accu_train = np.count_nonzero(is_pred_corr) / y_train.size\n",
        "print(f\"Training Accuracy {accu_train}\")\n",
        "next_i = error_indexes[0]\n",
        "W_update = X_train_homo[next_i] * y_train[next_i]\n",
        "W += W_update"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy 0.11428571428571428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNDn3LF7iohr",
        "outputId": "561bc73f-55cf-4878-b2f6-9b98a015899a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "pred = perceptron_predict(W, X_train_homo)\n",
        "is_pred_corr = y_train == pred\n",
        "is_pred_wrong = np.logical_not(is_pred_corr)\n",
        "error_indexes = np.nonzero(is_pred_wrong)[0]\n",
        "#find out where the prediction is INCORRECT\n",
        "accu_train = np.count_nonzero(is_pred_corr) / y_train.size\n",
        "print(f\"Training Accuracy {accu_train}\")\n",
        "next_i = error_indexes[0]\n",
        "W_update = X_train_homo[next_i] * y_train[next_i]\n",
        "W += W_update"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy 0.38095238095238093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGXcVFXiQ36f",
        "outputId": "c0e69386-2006-4482-ff4e-043142f0727e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "a = np.array([[1,2,3], [4,5,6]])\n",
        "b = np.array ([1,2,3])\n",
        "print(b, b.shape)\n",
        "print(a * b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2 3] (3,)\n",
            "[[ 1  4  9]\n",
            " [ 4 10 18]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbcEHKSOw1br"
      },
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "skperceptron = Perceptron()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA9rG-wPxBSc",
        "outputId": "35bf216b-cf8a-4c79-d059-7232bdc4733a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "skperceptron.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
              "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
              "           validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGqdn9xUxIrZ",
        "outputId": "0a047e86-f123-428a-9eb2-42b398d2703d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        }
      },
      "source": [
        "skperceptron.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmuFJvh5aosd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "simple_X_train, simple_X_valid, simple_y_train, simple_y_valid = \\\n",
        "    train_test_split(simple_X, simple_y)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}